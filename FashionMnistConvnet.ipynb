{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1QAUHjRYRtjbtwxsomVp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harrisson3/Breast-Cancer-Dataset/blob/main/FashionMnistConvnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2XQKv9tp_aC"
      },
      "outputs": [],
      "source": [
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "## Fashion-MNIST vs. MNIST Image Recognition\n",
        "\n",
        "This notebook compares the performance of a convolutional neural network (CNN) on the MNIST and Fashion-MNIST datasets.\n",
        "\n",
        "### Datasets:\n",
        "- **MNIST**: 28x28 grayscale images of handwritten digits (0-9).\n",
        "- **Fashion-MNIST**: 28x28 grayscale images of clothing articles, labeled in 10 categories:\n",
        "  - 0: T-shirt/top\n",
        "  - 1: Trouser\n",
        "  - 2: Pullover\n",
        "  - 3: Dress\n",
        "  - 4: Coat\n",
        "  - 5: Sandal\n",
        "  - 6: Shirt\n",
        "  - 7: Sneaker\n",
        "  - 8: Bag\n",
        "  - 9: Ankle boot\n",
        "- Each dataset contains 60,000 training samples and 10,000 test samples.\n",
        "\n",
        "### Tasks:\n",
        "1. Train a convnet on MNIST and Fashion-MNIST and compare performance.\n",
        "2. Evaluate training times.\n",
        "3. Add a Dense layer with 4096 neurons and analyze its impact.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load MNIST and Fashion-MNIST datasets\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
        "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
        "x_train_fashion, x_test_fashion = x_train_fashion / 255.0, x_test_fashion / 255.0\n",
        "\n",
        "# Expand dimensions for channels\n",
        "x_train_mnist = np.expand_dims(x_train_mnist, axis=-1)\n",
        "x_test_mnist = np.expand_dims(x_test_mnist, axis=-1)\n",
        "x_train_fashion = np.expand_dims(x_train_fashion, axis=-1)\n",
        "x_test_fashion = np.expand_dims(x_test_fashion, axis=-1)\n",
        "\n",
        "# Define a function to create the model\n",
        "def create_convnet(add_dense_layer=False):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.Flatten(),\n",
        "    ])\n",
        "\n",
        "    if add_dense_layer:\n",
        "        model.add(keras.layers.Dense(4096, activation='relu'))\n",
        "\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate models\n",
        "def train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test, add_dense_layer=False):\n",
        "    print(f\"Training on {dataset_name} with{'out' if not add_dense_layer else ''} additional Dense layer...\")\n",
        "    model = create_convnet(add_dense_layer)\n",
        "    start_time = time.time()\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=1, validation_split=0.1)\n",
        "    training_time = time.time() - start_time\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Test accuracy on {dataset_name}: {test_acc:.4f}, Training time: {training_time:.2f} sec\\n\")\n",
        "    return test_acc, training_time\n",
        "\n",
        "# Train models on both datasets\n",
        "results = {}\n",
        "for dataset_name, x_train, y_train, x_test, y_test in zip(\n",
        "    [\"MNIST\", \"Fashion-MNIST\"],\n",
        "    [x_train_mnist, x_train_fashion],\n",
        "    [y_train_mnist, y_train_fashion],\n",
        "    [x_test_mnist, x_test_fashion],\n",
        "    [y_test_mnist, y_test_fashion]\n",
        "):\n",
        "    results[dataset_name] = train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test)\n",
        "    results[dataset_name + \" + Dense 4096\"] = train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test, add_dense_layer=True)\n",
        "\n",
        "# Print summary\n",
        "for key, (acc, time) in results.items():\n",
        "    print(f\"{key}: Accuracy = {acc:.4f}, Training Time = {time:.2f} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq1UzZyfYLZ8",
        "outputId": "4b4fe672-df52-4f87-e907-037d8dc5321c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training on MNIST without additional Dense layer...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 75ms/step - accuracy: 0.8609 - loss: 0.4627 - val_accuracy: 0.9822 - val_loss: 0.0614\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 53ms/step - accuracy: 0.9817 - loss: 0.0575 - val_accuracy: 0.9877 - val_loss: 0.0460\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 55ms/step - accuracy: 0.9880 - loss: 0.0373 - val_accuracy: 0.9897 - val_loss: 0.0448\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 56ms/step - accuracy: 0.9907 - loss: 0.0290 - val_accuracy: 0.9893 - val_loss: 0.0404\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 53ms/step - accuracy: 0.9932 - loss: 0.0207 - val_accuracy: 0.9913 - val_loss: 0.0353\n",
            "Test accuracy on MNIST: 0.9904, Training time: 393.93 sec\n",
            "\n",
            "Training on MNIST with additional Dense layer...\n",
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 109ms/step - accuracy: 0.8793 - loss: 0.3770 - val_accuracy: 0.9828 - val_loss: 0.0583\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 111ms/step - accuracy: 0.9856 - loss: 0.0486 - val_accuracy: 0.9875 - val_loss: 0.0434\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 114ms/step - accuracy: 0.9900 - loss: 0.0328 - val_accuracy: 0.9887 - val_loss: 0.0388\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 115ms/step - accuracy: 0.9922 - loss: 0.0251 - val_accuracy: 0.9852 - val_loss: 0.0508\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 114ms/step - accuracy: 0.9925 - loss: 0.0234 - val_accuracy: 0.9908 - val_loss: 0.0348\n",
            "Test accuracy on MNIST: 0.9919, Training time: 711.97 sec\n",
            "\n",
            "Training on Fashion-MNIST without additional Dense layer...\n",
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 62ms/step - accuracy: 0.7083 - loss: 0.8196 - val_accuracy: 0.8605 - val_loss: 0.3878\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 60ms/step - accuracy: 0.8657 - loss: 0.3743 - val_accuracy: 0.8730 - val_loss: 0.3426\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 58ms/step - accuracy: 0.8876 - loss: 0.3079 - val_accuracy: 0.8898 - val_loss: 0.3071\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 59ms/step - accuracy: 0.8986 - loss: 0.2747 - val_accuracy: 0.8940 - val_loss: 0.2829\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 59ms/step - accuracy: 0.9069 - loss: 0.2507 - val_accuracy: 0.9032 - val_loss: 0.2796\n",
            "Test accuracy on Fashion-MNIST: 0.8959, Training time: 347.19 sec\n",
            "\n",
            "Training on Fashion-MNIST with additional Dense layer...\n",
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 117ms/step - accuracy: 0.7385 - loss: 0.7121 - val_accuracy: 0.8440 - val_loss: 0.4155\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - accuracy: 0.8803 - loss: 0.3253 - val_accuracy: 0.8805 - val_loss: 0.3208\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 113ms/step - accuracy: 0.8983 - loss: 0.2766 - val_accuracy: 0.8870 - val_loss: 0.3140\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 112ms/step - accuracy: 0.9080 - loss: 0.2427 - val_accuracy: 0.9050 - val_loss: 0.2622\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 110ms/step - accuracy: 0.9223 - loss: 0.2064 - val_accuracy: 0.9035 - val_loss: 0.2686\n",
            "Test accuracy on Fashion-MNIST: 0.9048, Training time: 621.25 sec\n",
            "\n",
            "MNIST: Accuracy = 0.9904, Training Time = 393.93 sec\n",
            "MNIST + Dense 4096: Accuracy = 0.9919, Training Time = 711.97 sec\n",
            "Fashion-MNIST: Accuracy = 0.8959, Training Time = 347.19 sec\n",
            "Fashion-MNIST + Dense 4096: Accuracy = 0.9048, Training Time = 621.25 sec\n"
          ]
        }
      ]
    }
  ]
}