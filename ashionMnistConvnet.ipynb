{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "ashionMnistConvnet.ipynb",
      "authorship_tag": "ABX9TyO9ZqpWcvZbx9j1H+KJLEkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harrisson3/Breast-Cancer-Dataset/blob/main/ashionMnistConvnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2XQKv9tp_aC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "## Fashion-MNIST vs. MNIST Image Recognition\n",
        "\n",
        "This notebook compares the performance of a convolutional neural network (CNN) on the MNIST and Fashion-MNIST datasets.\n",
        "\n",
        "### Datasets:\n",
        "- **MNIST**: 28x28 grayscale images of handwritten digits (0-9).\n",
        "- **Fashion-MNIST**: 28x28 grayscale images of clothing articles, labeled in 10 categories:\n",
        "  - 0: T-shirt/top\n",
        "  - 1: Trouser\n",
        "  - 2: Pullover\n",
        "  - 3: Dress\n",
        "  - 4: Coat\n",
        "  - 5: Sandal\n",
        "  - 6: Shirt\n",
        "  - 7: Sneaker\n",
        "  - 8: Bag\n",
        "  - 9: Ankle boot\n",
        "- Each dataset contains 60,000 training samples and 10,000 test samples.\n",
        "\n",
        "### Tasks:\n",
        "1. Train a convnet on MNIST and Fashion-MNIST and compare performance.\n",
        "2. Evaluate training times.\n",
        "3. Add a Dense layer with 4096 neurons and analyze its impact.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load MNIST and Fashion-MNIST datasets\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
        "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
        "x_train_fashion, x_test_fashion = x_train_fashion / 255.0, x_test_fashion / 255.0\n",
        "\n",
        "# Expand dimensions for channels\n",
        "x_train_mnist = np.expand_dims(x_train_mnist, axis=-1)\n",
        "x_test_mnist = np.expand_dims(x_test_mnist, axis=-1)\n",
        "x_train_fashion = np.expand_dims(x_train_fashion, axis=-1)\n",
        "x_test_fashion = np.expand_dims(x_test_fashion, axis=-1)\n",
        "\n",
        "# Define a function to create the model\n",
        "def create_convnet(add_dense_layer=False):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.Flatten(),\n",
        "    ])\n",
        "\n",
        "    if add_dense_layer:\n",
        "        model.add(keras.layers.Dense(4096, activation='relu'))\n",
        "\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate models\n",
        "def train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test, add_dense_layer=False):\n",
        "    print(f\"Training on {dataset_name} with{'out' if not add_dense_layer else ''} additional Dense layer...\")\n",
        "    model = create_convnet(add_dense_layer)\n",
        "    start_time = time.time()\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=1, validation_split=0.1)\n",
        "    training_time = time.time() - start_time\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Test accuracy on {dataset_name}: {test_acc:.4f}, Training time: {training_time:.2f} sec\\n\")\n",
        "    return test_acc, training_time\n",
        "\n",
        "# Train models on both datasets\n",
        "results = {}\n",
        "for dataset_name, x_train, y_train, x_test, y_test in zip(\n",
        "    [\"MNIST\", \"Fashion-MNIST\"],\n",
        "    [x_train_mnist, x_train_fashion],\n",
        "    [y_train_mnist, y_train_fashion],\n",
        "    [x_test_mnist, x_test_fashion],\n",
        "    [y_test_mnist, y_test_fashion]\n",
        "):\n",
        "    results[dataset_name] = train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test)\n",
        "    results[dataset_name + \" + Dense 4096\"] = train_and_evaluate(dataset_name, x_train, y_train, x_test, y_test, add_dense_layer=True)\n",
        "\n",
        "# Print summary\n",
        "for key, (acc, time) in results.items():\n",
        "    print(f\"{key}: Accuracy = {acc:.4f}, Training Time = {time:.2f} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq1UzZyfYLZ8",
        "outputId": "a1d185f3-4b46-4efa-8061-072ea39c096d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 55ms/step - accuracy: 0.8670 - loss: 0.4406 - val_accuracy: 0.9845 - val_loss: 0.0529\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 56ms/step - accuracy: 0.9822 - loss: 0.0566 - val_accuracy: 0.9877 - val_loss: 0.0399\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 54ms/step - accuracy: 0.9887 - loss: 0.0349 - val_accuracy: 0.9892 - val_loss: 0.0359\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 53ms/step - accuracy: 0.9913 - loss: 0.0272 - val_accuracy: 0.9907 - val_loss: 0.0324\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 55ms/step - accuracy: 0.9936 - loss: 0.0217 - val_accuracy: 0.9908 - val_loss: 0.0374\n",
            "Test accuracy on MNIST: 0.9892, Training time: 379.68 sec\n",
            "\n",
            "Training on MNIST with additional Dense layer...\n",
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 107ms/step - accuracy: 0.8942 - loss: 0.3267 - val_accuracy: 0.9807 - val_loss: 0.0616\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 106ms/step - accuracy: 0.9845 - loss: 0.0515 - val_accuracy: 0.9902 - val_loss: 0.0353\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 107ms/step - accuracy: 0.9899 - loss: 0.0326 - val_accuracy: 0.9913 - val_loss: 0.0316\n",
            "Epoch 4/5\n",
            "\u001b[1m412/844\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 105ms/step - accuracy: 0.9922 - loss: 0.0264"
          ]
        }
      ]
    }
  ]
}